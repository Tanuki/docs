---
title: Quickstart
description: Here you'll find information to get started quickly using Tanuki.
---

## Quickstart

Here you'll learn how to get started with Tanuki.ts with a basic classification example.

## Setup

### Install the package
<CodeBlock title="Install">
    ```bash
    npm install tanuki.ts
    npm install ts-patch --save-dev
    npx ts-patch install
    ```
</CodeBlock>

### Authenticate with your model provider

Add the API and authentication keys by setting environment variables.

You can do this by adding the following to your `.bashrc` or `.zshrc` file, or by running the following commands in your terminal.

<CodeBlocks>
  <CodeBlock title="Openai setup">
  ```bash
  export OPENAI_API_KEY=sk-...
  ```
  </CodeBlock>
    <CodeBlock title="Amazon Bedrock">
        ```bash
        export BEDROCK_API_KEY=sk-...
        ```
    </CodeBlock>
    <CodeBlock title="Together AI">
        ```bash
        export TOGETHER_API_KEY=sk-...
        ```
    </CodeBlock>
    <CodeBlock title="Anyscale">
        ```bash
        export ANYSCALE_API_KEY=sk-...
        ```
    </CodeBlock>
</CodeBlocks>

## Add Tanuki to your build system

## Default

Next, we need to add the Tanuki type transformer as a plugin to your `tsconfig.json` file.

This will allow Tanuki to be aware of your patched functions and types at runtime, as these types are erased when transpiling into Javascript.

```json
{
  "compilerOptions": {
    "plugins": [
      {
        "transform": "tanuki.ts/tanukiTransformer"
      }
    ]
  }
}
```

### Next.js Setup

As Next.js has its own internal build system, you must explicitly add the transformer to your `package.json` file instead by adding the following scripts.

```json
{
  "scripts": {
    "predev": "tanuki-type-compiler",
    "prebuild": "tanuki-type-compiler",
    "prestart": "tanuki-type-compiler"
  }
}
```

## Create a function

Create a Typescript class, and inside it create a static method decorated with `patch` containing type hints and a docstring.

<CodeBlock title="Patch">
    ```typescript
    import { patch, Tanuki } from "../../lib/tanuki";

    class SentimentClassifier {
        static classifySentiment = patch< "Good" | "Bad", string>()
            `Classify input objects`;
    }
    ```
</CodeBlock>

## Align the function (Optional)

Create a block using `Tanuki.align` containing Jest-like `expect` statements to calibrate the expected behaviour of your patched function with different inputs.

<Callout intent="info">
See the [align](placeholder_url) section for more information on how to use the `align` operator.
</Callout>

<CodeBlock title="Align">
    ```typescript
    import { Tanuki } from "../../lib/tanuki";

    Tanuki.align(async (it) => {
        it("declares how classifySentiment should behave", async (expect) => {
            await expect(ClassifierSentiment.classifySentiment("I love you")).toEqual('Good');
            await expect(ClassifierSentiment.classifySentiment("I hate you")).toEqual('Bad');
            await expect(ClassifierSentiment.classifySentiment("People from Phoenix are called Phoenicians")).toBeNull();
        })
    })
    ```
</CodeBlock>

## Configure the Tanuki runtime

By default, Tanuki uses GPT-4 as the teacher model.

You can configure your Tanuki runtime either by:
 - passing in the desired parameters to the `patch<>` operator.
 - globally setting Tanuki environment variables.

<Callout intent="info">
    See the [configuration](placeholder_url) API reference for more configuration options.
</Callout>

Here is an example of how to configure the Tanuki runtime to use the Llama model from Bedrock as the teacher model.

<CodeBlock title="Typescript">
```typescript
  class ClassifierSentiment {
    static classifySentiment = patch< "Good" | "Bad", string>({
        teacherModels: ["llama_70b_chat_aws"],
        generationParams: {
            "max_new_tokens": 10,
        }
    })`Classifies a message from the user into Good, Bad or null.`;
  }
```
</CodeBlock>

## Putting it all togther

<CodeBlock title="Typescript">
  ```typescript
  class ClassifierSentiment {
    static classifySentiment = patch< "Good" | "Bad", string>()
        `Classifies a message from the user into Good, Bad or null.`;
  }

  Tanuki.align(async (it) => {
     it("Specify how our functions should behave.", async (expect) => {
          await expect(ClassifierSentiment.classifySentiment("I love you")).toEqual('Good');
          await expect(ClassifierSentiment.classifySentiment("I hate you")).toEqual('Bad');
          await expect(ClassifierSentiment.classifySentiment("People from Phoenix are called Phoenicians")).toBeNull();
     })
  })

  console.log(await ClassifierSentiment.classifySentiment("I like you")) // Good
  console.log(await ClassifierSentiment.classifySentiment("Apples might be red")) // null
  ```
</CodeBlock>


## Next steps
<br />
<Cards>
    <Card
        title="Learn how to create more complex functions and aligns"
        icon="fa-book"
        href="/api-reference/python"
    />
    <Card
        title="Learn how to use different teacher and student models"
        icon="fa-graduation-cap"
        href="/api-reference/python"
    />
    <Card
        title="Learn how Tanuki distills larger models down to smaller models"
        icon="fa-flask"
        href="/api-reference/python"
    />
    <Card
        title="See examples of what else you can do with Tanuki"
        icon="fa-lightbulb"
        href="/api-reference/python"
    />
</Cards>
<br />